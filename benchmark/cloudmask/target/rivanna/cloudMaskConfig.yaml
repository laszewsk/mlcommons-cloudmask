# config.yml

# SciML-Bench
# Copyright Â© 2022 Scientific Machine Learning Research Group
# Scientific Computing Department, Rutherford Appleton Laboratory
# Science and Technology Facilities Council, UK. 
# All rights reserved.

# This is a configuration file for the CloudMask benchmark.

# General info
benchmark: CloudMask
organisation: STFC
division: SciML
status: research
platform: nvidia gtx-2
accelerators_per_node: 16

# Training data
train_dir: /scratch/USERTOREPLACE/mlcommons/benchmarks/cloudmask/data/one-day

# Inference data
inference_dir: /scratch/USERTOREPLACE/mlcommons/benchmarks/cloudmask/data/ssts

# Model file
model_file : ~/sciml_bench/outputs/slstr_cloud/cloudModel.h5

# Output directory
output_dir : ~/sciml_bench/outputs/slstr_cloud

# Log file for recording runtimes
log_file: ./cloudMask_Log

# Log file for MLCommons logging
mlperf_logfile: ./mlperf_cloudmask.log

# Size of each patch to feed to the network
PATCH_SIZE: 256

# Original height of the image
IMAGE_H: 1200

# Original width of the image
IMAGE_W: 1500

# No. of channels
N_CHANNELS: 9

# Min allowable SST
MIN_SST: 273.15

# Amount to crop the edges of the images by
CROP_SIZE: 80

# Hyperparameters
seed: 1234

learning_rate: 0.001

epochs: 1

batch_size: 32

train_split: 0.8

clip_offset: 15

no_cache: False

nodes: 1

gpu: 2



